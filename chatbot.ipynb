{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b4af46-2ecd-4a64-857a-3bd4171163fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8edb8304-df60-4097-8ef7-3f771cd33f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9dd052-09d4-4342-ad8b-f32bb9e2ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_assistant(thread, run):\n",
    "    \"\"\"\n",
    "        Function to periodically check run status of AI assistant and print run time\n",
    "    \"\"\"\n",
    "\n",
    "    # wait for assistant process prompt\n",
    "    t0 = time.time()\n",
    "    while run.status != 'completed':\n",
    "\n",
    "        # retreive status of run (this might take a few seconds or more)\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id\n",
    "        )\n",
    "\n",
    "        # wait 0.5 seconds\n",
    "        time.sleep(0.25)\n",
    "    dt = time.time() - t0\n",
    "    print(\"Elapsed time: \" + str(dt) + \" seconds\")\n",
    "    \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd256538-ea1e-4340-acb7-78fdfe03dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_zGr7sdvWWQWlLMoGUrArk8GW', created_at=1732968549, description='GPT for daily communication and responses', instructions=\"GPT2675, is a chatbot meant to generate responses like human beings in daily communication. It reacts to feedback aptly and concludes with its signature '–GPT2675'. GPT2675 will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\", metadata={}, model='gpt-4-0125-preview', name='GPT2675', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)\n"
     ]
    }
   ],
   "source": [
    "intstructions_string = \"GPT2675, is a chatbot meant to generate responses like human beings in daily communication. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–GPT2675'. \\\n",
    "GPT2675 will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\"\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"GPT2675\",\n",
    "    description=\"GPT for daily communication and responses\",\n",
    "    instructions=intstructions_string,\n",
    "    model=\"gpt-4-0125-preview\"\n",
    ")\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc218e2-3fb3-4475-875e-0feccad0c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create thread (i.e. object that handles conversations between user and assistant)\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate user message\n",
    "user_message = \"Great content, thank you!\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "554a9ac1-b799-407a-b2d3-85a135d599bb",
   "metadata": {},
   "source": [
    "The above code cell handles conversations between a user and an assistant, related to OpenAI's API. The code above creates a new conversation thread, adds a user message, and then sends this message to the assistant to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6157075-0318-4957-8fd1-d5b6697dda53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.1113355159759521 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'run_Cvd3jV3CyP9Ge9d9ePllWyjt',\n",
       " 'assistant_id': 'asst_zGr7sdvWWQWlLMoGUrArk8GW',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1732968560,\n",
       " 'created_at': 1732968558,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': \"GPT2675, is a chatbot meant to generate responses like human beings in daily communication. It reacts to feedback aptly and concludes with its signature '–GPT2675'. GPT2675 will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\",\n",
       " 'last_error': None,\n",
       " 'max_completion_tokens': None,\n",
       " 'max_prompt_tokens': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-0125-preview',\n",
       " 'object': 'thread.run',\n",
       " 'parallel_tool_calls': True,\n",
       " 'required_action': None,\n",
       " 'response_format': 'auto',\n",
       " 'started_at': 1732968559,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_T2Wlzt9awFPa6QXFPzvZHXPh',\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'truncation_strategy': TruncationStrategy(type='auto', last_messages=None),\n",
       " 'usage': Usage(completion_tokens=35, prompt_tokens=101, total_tokens=136, prompt_token_details={'cached_tokens': 0}),\n",
       " 'temperature': 1.0,\n",
       " 'top_p': 1.0,\n",
       " 'tool_resources': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)\n",
    "\n",
    "# view run object (in Jupyter Lab)\n",
    "dict(run)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "234129d6-5917-4d12-9c4e-74a627b63a9f",
   "metadata": {},
   "source": [
    "The above code cell waits for the assistant to process the prompt and prints the response in the form of a dictionary."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc6dca2f-4578-4157-a365-cef0628fea07",
   "metadata": {},
   "source": [
    "We implemented a custom AI assistant using zero shot prompting that is we didn't provide any training examples to the assistant.\n",
    "We can use few shot prompting by providing some training examples to the assistant so that it can generate better responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be351e-8949-4192-b9da-6b28348b1c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
